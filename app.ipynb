{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of dataset:\n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
      "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     1       1  \n",
      "1   0     2       1  \n",
      "2   0     2       1  \n",
      "3   0     2       1  \n",
      "4   0     2       1  \n",
      "\n",
      "Info dataset:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n",
      "\n",
      "Statistik deskriptif:\n",
      "               age         sex          cp    trestbps        chol         fbs  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
      "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
      "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
      "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
      "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
      "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
      "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
      "\n",
      "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
      "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
      "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
      "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
      "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
      "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
      "\n",
      "             thal      target  \n",
      "count  303.000000  303.000000  \n",
      "mean     2.313531    0.544554  \n",
      "std      0.612277    0.498835  \n",
      "min      0.000000    0.000000  \n",
      "25%      2.000000    0.000000  \n",
      "50%      2.000000    1.000000  \n",
      "75%      3.000000    1.000000  \n",
      "max      3.000000    1.000000  \n",
      "\n",
      "Missing values:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24  5]\n",
      " [ 5 27]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.84      0.84      0.84        32\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.84      0.84      0.84        61\n",
      "weighted avg       0.84      0.84      0.84        61\n",
      "\n",
      "\n",
      "Accuracy Score: 0.8360655737704918\n",
      "Data tes 1 bernilai 1 atau memiliki penyakit jantung.\n",
      "Data tes 2 bernilai 1 atau memiliki penyakit jantung.\n",
      "Data tes 3 bernilai 1 atau memiliki penyakit jantung.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\62813\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import library yang diperlukan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'heart.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Eksplorasi dataset\n",
    "print(\"Head of dataset:\\n\", data.head())\n",
    "print(\"\\nInfo dataset:\\n\")\n",
    "data.info()\n",
    "print(\"\\nStatistik deskriptif:\\n\", data.describe())\n",
    "\n",
    "# Cek missing values\n",
    "print(\"\\nMissing values:\\n\", data.isnull().sum())\n",
    "\n",
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = data.drop(columns=['target'])  # 'target' adalah kolom prediksi\n",
    "y = data['target']\n",
    "\n",
    "# Normalisasi fitur numerik (opsional, tergantung model)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset menjadi training dan testing (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pilih model (Random Forest Classifier)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Latih model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi pada data testing\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Buat 10 data uji secara manual untuk pengujian\n",
    "new_data = np.array([\n",
    "    [63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1],\n",
    "    [37, 0, 2, 130, 250, 0, 1, 187, 0, 3.5, 1, 0, 2],\n",
    "    [41, 1, 1, 130, 204, 0, 0, 172, 0, 1.4, 1, 0, 3],\n",
    "    # [56, 1, 1, 120, 236, 0, 1, 178, 0, 0.8, 1, 0, 3],\n",
    "    # [57, 0, 0, 140, 241, 0, 1, 123, 1, 0.2, 1, 0, 3],\n",
    "    # [57, 1, 0, 120, 354, 0, 1, 163, 1, 0.6, 1, 0, 3],\n",
    "    # [60, 1, 2, 140, 294, 0, 1, 153, 0, 2.0, 1, 2, 7],\n",
    "    # [62, 0, 0, 160, 164, 0, 1, 145, 0, 6.2, 1, 3, 3],\n",
    "    # [64, 1, 0, 120, 221, 0, 1, 106, 0, 5.6, 1, 0, 7],\n",
    "    # [59, 1, 0, 140, 177, 0, 1, 162, 1, 0.0, 2, 1, 7]\n",
    "])\n",
    "\n",
    "# Normalisasi data uji\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Prediksi data uji\n",
    "new_predictions = model.predict(new_data_scaled)\n",
    "for i, prediction in enumerate(new_predictions):\n",
    "    status = \"memiliki penyakit jantung\" if prediction == 1 else \"tidak memiliki penyakit jantung\"\n",
    "    print(f\"Data tes {i+1} bernilai {prediction} atau {status}.\")\n",
    "\n",
    "# Penjelasan penggunaan:\n",
    "# 1. Pastikan data sudah di-preprocess dengan format yang sama seperti data training.\n",
    "# 2. Gunakan scaler yang sama untuk normalisasi data baru.\n",
    "# 3. Gunakan model yang sudah dilatih untuk melakukan prediksi terhadap data baru.\n",
    "# 4. Interpretasi hasil prediksi: 1 = memiliki penyakit jantung, 0 = tidak memiliki penyakit jantung.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
